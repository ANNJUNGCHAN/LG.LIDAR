{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDCFE Model\n",
    "- Seperate Dense Concat Fold Ensenble Model\n",
    "- 연관이 있는 열을 하나로 묶고, 연관성이 있는 그룹들 각각을 Dense layer로 차원을 축소하여 잠재벡터를 만듦.\n",
    "- 이후, 해당 잠재 벡터들을 모두 병합함(Concat)\n",
    "- KFOLD 5 로 5개의 모델을 각각 생성하고, 모델들을 저장한 후, Ensemble Method를 사용하여 5개의 모델을 모두 앙상블 시킴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패키지 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# fix seed\n",
    "import random\n",
    "import os\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42)\n",
    "\n",
    "# Tensorflow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Dense,Dropout,BatchNormalization,Add,Input,Activation,Concatenate,Average\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "# scoring\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"C:/LG_Aimers/data/Train-Test-Split/X_train.csv\")\n",
    "y = pd.read_csv(\"C:/LG_Aimers/data/Train-Test-Split/y_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate\n",
    "- 연관이 있는 열을 하나로 묶음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연관이 있는 열을 하나로 묶는 과정\n",
    "PCB_press = X[[\"X_01\",\"X_02\",\"X_05\",\"X_06\"]]\n",
    "material_weight = X[[\"X_03\",\"X_10\",\"X_11\"]]\n",
    "material_area = X[[\"X_07\",\"X_08\",\"X_09\"]]\n",
    "pad_loc = X[[\"X_14\",\"X_15\",\"X_16\",\"X_17\",\"X_18\",\"X_13\"]]\n",
    "screw1_deep = X[[\"X_19\",\"X_20\",\"X_21\",\"X_22\"]]\n",
    "connect_pin = X[[\"X_24\",\"X_25\",\"X_26\",\"X_27\",\"X_28\",\"X_29\",\"X_12\"]]\n",
    "screw2_deep = X[[\"X_30\",\"X_31\",\"X_32\",\"X_33\"]]\n",
    "screw_rotate = X[[\"X_34\",\"X_35\",\"X_36\",\"X_37\"]]\n",
    "housing = X[[\"X_38\",\"X_39\",\"X_40\",\"X_46\"]]\n",
    "radom = X[[\"X_41\",\"X_42\",\"X_43\",\"X_44\",\"X_45\"]]\n",
    "RF = X[[\"X_49\",\"X_50\",\"X_51\",\"X_52\",\"X_53\",\"X_54\",\"X_55\",\"X_56\"]]\n",
    "\n",
    "# 딥러닝 모델 학습을 위해 넘파이 형태로 데이터 변환\n",
    "PCB_press = np.array(PCB_press)\n",
    "material_weight = np.array(material_weight)\n",
    "material_area = np.array(material_area)\n",
    "pad_loc = np.array(pad_loc)\n",
    "screw1_deep = np.array(screw1_deep)\n",
    "connect_pin = np.array(connect_pin)\n",
    "screw2_deep = np.array(screw2_deep)\n",
    "screw_rotate = np.array(screw_rotate)\n",
    "housing = np.array(housing)\n",
    "radom = np.array(radom)\n",
    "RF = np.array(RF)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### input 정의 : 연관 있는 열들을 모두 각각의 input으로 형성\n",
    "PCB_press_input = keras.layers.Input(shape=(4,), name=\"PCB_press_input\", dtype=\"float32\")\n",
    "material_weight_input = keras.layers.Input(shape=(3,), name=\"material_weight_input\", dtype=\"float32\")\n",
    "material_area_input = keras.layers.Input(shape=(3,), name=\"material_area_input\", dtype=\"float32\")\n",
    "pad_loc_input = keras.layers.Input(shape=(6,), name=\"pad_loc_input\", dtype=\"float32\")\n",
    "screw1_deep_input = keras.layers.Input(shape=(4,), name=\"screw1_deep_input\", dtype=\"float32\")\n",
    "connect_pin_input = keras.layers.Input(shape=(7,), name=\"connect_pin_input\", dtype=\"float32\")\n",
    "screw2_deep_input = keras.layers.Input(shape=(4,), name=\"screw2_deep_input\", dtype=\"float32\")\n",
    "screw_rotate_input = keras.layers.Input(shape=(4,), name=\"screw_rotate_input\", dtype=\"float32\")\n",
    "housing_input = keras.layers.Input(shape=(4,), name=\"housing_input\", dtype=\"float32\")\n",
    "radom_input = keras.layers.Input(shape=(5,), name=\"radom_input\", dtype=\"float32\")\n",
    "RF_input = keras.layers.Input(shape=(8,), name=\"RF_input\", dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dense layer를 이용하여 Seperate 된 각각의 열들의 집합들의 잠재벡터를 하나씩 추출해줌\n",
    "\n",
    "# PCB_press\n",
    "PCB_press_layer1 = keras.layers.Dense(256, activation=\"relu\")(PCB_press_input)\n",
    "PCB_press_layer2 = keras.layers.Dense(128, activation=\"relu\")(PCB_press_layer1)\n",
    "PCB_press_layer3 = keras.layers.Dense(256, activation=\"relu\")(PCB_press_layer2)\n",
    "PCB_press_layer4 = keras.layers.Dense(4, activation=\"relu\")(PCB_press_layer3)\n",
    "\n",
    "# material_weight\n",
    "material_weight_layer1 = keras.layers.Dense(256, activation=\"relu\")(material_weight_input)\n",
    "material_weight_layer2 = keras.layers.Dense(128, activation=\"relu\")(material_weight_layer1)\n",
    "material_weight_layer3 = keras.layers.Dense(256, activation=\"relu\")(material_weight_layer2)\n",
    "material_weight_layer4 = keras.layers.Dense(3, activation=\"relu\")(material_weight_layer3)\n",
    "\n",
    "# material_area\n",
    "material_area_layer1 = keras.layers.Dense(256, activation=\"relu\")(material_area_input)\n",
    "material_area_layer2 = keras.layers.Dense(128, activation=\"relu\")(material_area_layer1)\n",
    "material_area_layer3 = keras.layers.Dense(256, activation=\"relu\")(material_area_layer2)\n",
    "material_area_layer4 = keras.layers.Dense(3, activation=\"relu\")(material_area_layer3)\n",
    "\n",
    "# pad_loc\n",
    "pad_loc_layer1 = keras.layers.Dense(256, activation=\"relu\")(pad_loc_input)\n",
    "pad_loc_layer2 = keras.layers.Dense(128, activation=\"relu\")(pad_loc_layer1)\n",
    "pad_loc_layer3 = keras.layers.Dense(256, activation=\"relu\")(pad_loc_layer2)\n",
    "pad_loc_layer4 = keras.layers.Dense(6, activation=\"relu\")(pad_loc_layer3)\n",
    "\n",
    "# screw1_deep\n",
    "screw1_deep_layer1 = keras.layers.Dense(256, activation=\"relu\")(screw1_deep_input)\n",
    "screw1_deep_layer2 = keras.layers.Dense(128, activation=\"relu\")(screw1_deep_layer1)\n",
    "screw1_deep_layer3 = keras.layers.Dense(256, activation=\"relu\")(screw1_deep_layer2) \n",
    "screw1_deep_layer4 = keras.layers.Dense(4, activation=\"relu\")(screw1_deep_layer3)\n",
    "\n",
    "# connect_pin\n",
    "connect_pin_layer1 = keras.layers.Dense(256, activation=\"relu\")(connect_pin_input)\n",
    "connect_pin_layer2 = keras.layers.Dense(128, activation=\"relu\")(connect_pin_layer1)\n",
    "connect_pin_layer3 = keras.layers.Dense(256, activation=\"relu\")(connect_pin_layer2)\n",
    "connect_pin_layer4 = keras.layers.Dense(7, activation=\"relu\")(connect_pin_layer3)\n",
    "\n",
    "# screw2_deep\n",
    "screw2_deep_layer1 = keras.layers.Dense(256, activation=\"relu\")(screw2_deep_input)\n",
    "screw2_deep_layer2 = keras.layers.Dense(128, activation=\"relu\")(screw2_deep_layer1)\n",
    "screw2_deep_layer3 = keras.layers.Dense(256, activation=\"relu\")(screw2_deep_layer2)\n",
    "screw2_deep_layer4 = keras.layers.Dense(4, activation=\"relu\")(screw2_deep_layer3)\n",
    "\n",
    "# screw_rotate\n",
    "screw_rotate_layer1 = keras.layers.Dense(256, activation=\"relu\")(screw_rotate_input)\n",
    "screw_rotate_layer2 = keras.layers.Dense(128, activation=\"relu\")(screw_rotate_layer1)\n",
    "screw_rotate_layer3 = keras.layers.Dense(256, activation=\"relu\")(screw_rotate_layer2)\n",
    "screw_rotate_layer4 = keras.layers.Dense(4, activation=\"relu\")(screw_rotate_layer3)\n",
    "\n",
    "# housing\n",
    "housing_layer1 = keras.layers.Dense(256, activation=\"relu\")(housing_input)\n",
    "housing_layer2 = keras.layers.Dense(128, activation=\"relu\")(housing_layer1)\n",
    "housing_layer3 = keras.layers.Dense(256, activation=\"relu\")(housing_layer2)\n",
    "housing_layer4 = keras.layers.Dense(4, activation=\"relu\")(housing_layer3)\n",
    "\n",
    "# radom\n",
    "radom_layer1 = keras.layers.Dense(256, activation=\"relu\")(radom_input)\n",
    "radom_layer2 = keras.layers.Dense(128, activation=\"relu\")(radom_layer1)\n",
    "radom_layer3 = keras.layers.Dense(256, activation=\"relu\")(radom_layer2)\n",
    "radom_layer4 = keras.layers.Dense(5, activation=\"relu\")(radom_layer3)\n",
    "\n",
    "# RF\n",
    "RF_layer1 = keras.layers.Dense(256, activation=\"relu\")(RF_input)\n",
    "RF_layer2 = keras.layers.Dense(128, activation=\"relu\")(RF_layer1)\n",
    "RF_layer3 = keras.layers.Dense(256, activation=\"relu\")(RF_layer2)\n",
    "RF_layer4 = keras.layers.Dense(8, activation=\"relu\")(RF_layer3)\n",
    "\n",
    "### 생성된 잠재벡터들을 하나의 layer에서 모두 병합시켜줌\n",
    "# concat\n",
    "concat_layer = keras.layers.concatenate([PCB_press_layer4, material_weight_layer4, material_area_layer4, pad_loc_layer4, screw1_deep_layer4, connect_pin_layer4, screw2_deep_layer4, screw_rotate_layer4, housing_layer4, radom_layer4, RF_layer4])\n",
    "\n",
    "### 결과가 나오도록 함\n",
    "# result\n",
    "result_layer = keras.layers.Dense(14)(concat_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 적합 함수 생성\n",
    "def fit_model(PCB_press_train,material_weight_train,material_area_train,pad_loc_train,screw1_deep_train,connect_pin_train,screw2_deep_train,screw_rotate_train,housing_train,radom_train,RF_train,PCB_press_val,material_weight_val,material_area_val,pad_loc_val,screw1_deep_val,connect_pin_val,screw2_deep_val,screw_rotate_val,housing_val,radom_val,RF_val,y_train,y_val,i): \n",
    "    ### 모델 정의\n",
    "    model = keras.Model(\n",
    "        inputs=[PCB_press_input,material_weight_input,material_area_input,pad_loc_input,screw1_deep_input,connect_pin_input,screw2_deep_input,screw_rotate_input,housing_input,radom_input,RF_input], \n",
    "        outputs=result_layer)\n",
    "    \n",
    "    ### 모델 컴파일\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    ### early stopping option 걸기\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "    \n",
    "    ### checkpoint 옵션 걸기 -> fold 내에서 모델이 개선되는 시점의 모델을 h5 형태로 저장시킴\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath = 'C:/LG_Aimers/Conv/model/'+'fold' + str(i) + '--.{val_loss:.3f}'+'.h5', \n",
    "        monitor='val_loss', \n",
    "        save_best_only=True)\n",
    "\n",
    "    ### model fitting\n",
    "    model.fit([PCB_press_train,material_weight_train,material_area_train,pad_loc_train,screw1_deep_train,connect_pin_train,screw2_deep_train,screw_rotate_train,housing_train,radom_train,RF_train], \n",
    "              y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100, \n",
    "              validation_data=([PCB_press_val,material_weight_val,material_area_val,pad_loc_val,screw1_deep_val,connect_pin_val,screw2_deep_val,screw_rotate_val,housing_val,radom_val,RF_val], y_val), \n",
    "              callbacks=[early_stopping, checkpoint])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "793/793 [==============================] - 9s 10ms/step - loss: 274.6530 - val_loss: 1.7292\n",
      "Epoch 2/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.6684 - val_loss: 1.7160\n",
      "Epoch 3/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.6365 - val_loss: 1.6474\n",
      "Epoch 4/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.6231 - val_loss: 1.6986\n",
      "Epoch 5/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.6231 - val_loss: 1.6208\n",
      "Epoch 6/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.6107 - val_loss: 1.6214\n",
      "Epoch 7/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.6025 - val_loss: 1.5963\n",
      "Epoch 8/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.6023 - val_loss: 1.5881\n",
      "Epoch 9/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.6016 - val_loss: 1.8346\n",
      "Epoch 10/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5986 - val_loss: 1.5975\n",
      "Epoch 11/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5920 - val_loss: 1.6215\n",
      "Epoch 12/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5958 - val_loss: 1.5866\n",
      "Epoch 13/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5857 - val_loss: 1.5812\n",
      "Epoch 14/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5918 - val_loss: 1.6098\n",
      "Epoch 15/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5858 - val_loss: 1.6129\n",
      "Epoch 16/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5898 - val_loss: 1.6281\n",
      "Epoch 17/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5887 - val_loss: 1.6503\n",
      "Epoch 18/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5794 - val_loss: 1.5790\n",
      "Epoch 19/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5823 - val_loss: 1.5747\n",
      "Epoch 20/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5812 - val_loss: 1.5794\n",
      "Epoch 21/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5825 - val_loss: 1.5964\n",
      "Epoch 22/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5752 - val_loss: 1.6104\n",
      "Epoch 23/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5775 - val_loss: 1.5826\n",
      "Epoch 24/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5802 - val_loss: 1.5725\n",
      "Epoch 25/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5764 - val_loss: 1.5874\n",
      "Epoch 26/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5762 - val_loss: 1.5848\n",
      "Epoch 27/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5767 - val_loss: 1.5982\n",
      "Epoch 28/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5718 - val_loss: 1.5957\n",
      "Epoch 29/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5737 - val_loss: 1.5915\n",
      "Epoch 30/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5759 - val_loss: 1.5773\n",
      "Epoch 31/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5727 - val_loss: 1.5948\n",
      "Epoch 32/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5687 - val_loss: 1.7251\n",
      "Epoch 33/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5719 - val_loss: 1.8186\n",
      "Epoch 34/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5763 - val_loss: 1.6453\n",
      "Epoch 35/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5688 - val_loss: 1.5855\n",
      "Epoch 36/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5690 - val_loss: 1.5730\n",
      "Epoch 37/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5688 - val_loss: 1.6042\n",
      "Epoch 38/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5749 - val_loss: 1.5824\n",
      "Epoch 39/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5695 - val_loss: 1.5873\n",
      "Epoch 40/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5700 - val_loss: 1.5858\n",
      "Epoch 41/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5684 - val_loss: 1.5691\n",
      "Epoch 42/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5700 - val_loss: 1.5767\n",
      "Epoch 43/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5679 - val_loss: 1.6134\n",
      "Epoch 44/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5661 - val_loss: 1.5881\n",
      "Epoch 45/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5700 - val_loss: 1.5656\n",
      "Epoch 46/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5644 - val_loss: 1.6094\n",
      "Epoch 47/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5644 - val_loss: 1.5713\n",
      "Epoch 48/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5665 - val_loss: 1.6411\n",
      "Epoch 49/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5627 - val_loss: 1.5636\n",
      "Epoch 50/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5639 - val_loss: 1.5714\n",
      "Epoch 51/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5617 - val_loss: 1.5851\n",
      "Epoch 52/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5664 - val_loss: 1.6971\n",
      "Epoch 53/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5640 - val_loss: 1.5854\n",
      "Epoch 54/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5614 - val_loss: 1.6307\n",
      "Epoch 55/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5605 - val_loss: 1.6020\n",
      "Epoch 56/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5628 - val_loss: 1.5599\n",
      "Epoch 57/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5614 - val_loss: 1.5755\n",
      "Epoch 58/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5645 - val_loss: 1.6534\n",
      "Epoch 59/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5680 - val_loss: 1.5616\n",
      "Epoch 60/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5595 - val_loss: 1.6605\n",
      "Epoch 61/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5598 - val_loss: 1.6356\n",
      "Epoch 62/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5596 - val_loss: 1.5599\n",
      "Epoch 63/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5607 - val_loss: 1.6241\n",
      "Epoch 64/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5627 - val_loss: 1.5981\n",
      "Epoch 65/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5595 - val_loss: 1.6116\n",
      "Epoch 66/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5608 - val_loss: 1.6074\n",
      "Epoch 67/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5583 - val_loss: 1.5806\n",
      "Epoch 68/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5565 - val_loss: 1.5865\n",
      "Epoch 69/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5597 - val_loss: 1.5694\n",
      "Epoch 70/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5592 - val_loss: 1.5666\n",
      "Epoch 71/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5579 - val_loss: 1.5672\n",
      "Epoch 72/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5582 - val_loss: 1.6199\n",
      "Epoch 73/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5590 - val_loss: 1.5789\n",
      "Epoch 74/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5586 - val_loss: 1.5857\n",
      "Epoch 75/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5609 - val_loss: 1.6145\n",
      "Epoch 76/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5621 - val_loss: 1.5604\n",
      "Epoch 77/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5598 - val_loss: 1.5983\n",
      "Epoch 78/100\n",
      "793/793 [==============================] - 8s 10ms/step - loss: 1.5588 - val_loss: 1.6089\n",
      "Epoch 79/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5590 - val_loss: 1.7616\n",
      "Epoch 80/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5568 - val_loss: 1.5609\n",
      "Epoch 81/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5540 - val_loss: 1.6710\n",
      "Epoch 82/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5586 - val_loss: 1.5576\n",
      "Epoch 83/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5590 - val_loss: 1.5679\n",
      "Epoch 84/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5561 - val_loss: 1.5706\n",
      "Epoch 85/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5556 - val_loss: 1.5869\n",
      "Epoch 86/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5560 - val_loss: 1.5699\n",
      "Epoch 87/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5547 - val_loss: 1.5569\n",
      "Epoch 88/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5568 - val_loss: 1.6721\n",
      "Epoch 89/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5596 - val_loss: 1.5628\n",
      "Epoch 90/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5536 - val_loss: 1.6266\n",
      "Epoch 91/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5598 - val_loss: 1.5928\n",
      "Epoch 92/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5566 - val_loss: 1.5611\n",
      "Epoch 93/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5567 - val_loss: 1.5841\n",
      "Epoch 94/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5554 - val_loss: 1.6372\n",
      "Epoch 95/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5550 - val_loss: 1.5600\n",
      "Epoch 96/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5576 - val_loss: 1.5677\n",
      "Epoch 97/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5554 - val_loss: 1.5685\n",
      "Epoch 98/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5569 - val_loss: 1.5900\n",
      "Epoch 99/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5550 - val_loss: 1.5687\n",
      "Epoch 100/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5560 - val_loss: 1.5665\n",
      "finish 1 model\n",
      "Epoch 1/100\n",
      "793/793 [==============================] - 9s 9ms/step - loss: 1.5395 - val_loss: 1.6194\n",
      "Epoch 2/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5357 - val_loss: 1.6662\n",
      "Epoch 3/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5432 - val_loss: 1.6359\n",
      "Epoch 4/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5418 - val_loss: 1.6301\n",
      "Epoch 5/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5401 - val_loss: 1.6337\n",
      "Epoch 6/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5381 - val_loss: 1.6185\n",
      "Epoch 7/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5408 - val_loss: 1.6373\n",
      "Epoch 8/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5385 - val_loss: 1.6467\n",
      "Epoch 9/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5384 - val_loss: 1.6360\n",
      "Epoch 10/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5379 - val_loss: 1.6247\n",
      "Epoch 11/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5364 - val_loss: 1.6532\n",
      "Epoch 12/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5398 - val_loss: 1.6334\n",
      "Epoch 13/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5387 - val_loss: 1.6778\n",
      "Epoch 14/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5402 - val_loss: 1.6387\n",
      "Epoch 15/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5364 - val_loss: 1.6525\n",
      "Epoch 16/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5374 - val_loss: 1.6230\n",
      "Epoch 17/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5407 - val_loss: 1.6658\n",
      "Epoch 18/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5378 - val_loss: 1.6353\n",
      "Epoch 19/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5405 - val_loss: 1.6253\n",
      "Epoch 20/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5354 - val_loss: 1.6322\n",
      "Epoch 21/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5399 - val_loss: 1.6260\n",
      "Epoch 22/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5387 - val_loss: 1.6208\n",
      "Epoch 23/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5365 - val_loss: 1.6454\n",
      "Epoch 24/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5384 - val_loss: 1.6582\n",
      "Epoch 25/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5385 - val_loss: 1.6442\n",
      "Epoch 26/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5360 - val_loss: 1.6203\n",
      "finish 2 model\n",
      "Epoch 1/100\n",
      "793/793 [==============================] - 9s 10ms/step - loss: 1.5495 - val_loss: 1.5758\n",
      "Epoch 2/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5503 - val_loss: 1.5694\n",
      "Epoch 3/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5493 - val_loss: 1.5891\n",
      "Epoch 4/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5500 - val_loss: 1.5803\n",
      "Epoch 5/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5502 - val_loss: 1.5936\n",
      "Epoch 6/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5467 - val_loss: 1.5772\n",
      "Epoch 7/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5488 - val_loss: 1.5994\n",
      "Epoch 8/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5501 - val_loss: 1.5816\n",
      "Epoch 9/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5508 - val_loss: 1.5775\n",
      "Epoch 10/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5486 - val_loss: 1.5937\n",
      "Epoch 11/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5464 - val_loss: 1.5839\n",
      "Epoch 12/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5525 - val_loss: 1.5771\n",
      "Epoch 13/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5496 - val_loss: 1.5861\n",
      "Epoch 14/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5507 - val_loss: 1.5903\n",
      "Epoch 15/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5498 - val_loss: 1.5982\n",
      "Epoch 16/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5478 - val_loss: 1.5826\n",
      "Epoch 17/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5483 - val_loss: 1.5783\n",
      "Epoch 18/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5507 - val_loss: 1.5684\n",
      "Epoch 19/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5512 - val_loss: 1.5689\n",
      "Epoch 20/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5495 - val_loss: 1.6125\n",
      "Epoch 21/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5487 - val_loss: 1.6313\n",
      "Epoch 22/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5460 - val_loss: 1.5766\n",
      "Epoch 23/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5508 - val_loss: 1.5729\n",
      "Epoch 24/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5473 - val_loss: 1.5702\n",
      "Epoch 25/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5485 - val_loss: 1.6256\n",
      "Epoch 26/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5503 - val_loss: 1.5708\n",
      "Epoch 27/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5486 - val_loss: 1.5791\n",
      "Epoch 28/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5464 - val_loss: 1.6274\n",
      "Epoch 29/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5474 - val_loss: 1.5863\n",
      "Epoch 30/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5485 - val_loss: 1.5724\n",
      "Epoch 31/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5476 - val_loss: 1.5709\n",
      "Epoch 32/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5486 - val_loss: 1.5696\n",
      "Epoch 33/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5456 - val_loss: 1.5826\n",
      "Epoch 34/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5475 - val_loss: 1.5726\n",
      "Epoch 35/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5472 - val_loss: 1.5706\n",
      "Epoch 36/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5503 - val_loss: 1.5697\n",
      "Epoch 37/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5492 - val_loss: 1.6515\n",
      "Epoch 38/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5476 - val_loss: 1.5781\n",
      "finish 3 model\n",
      "Epoch 1/100\n",
      "793/793 [==============================] - 9s 10ms/step - loss: 1.5735 - val_loss: 1.4668\n",
      "Epoch 2/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5729 - val_loss: 1.4880\n",
      "Epoch 3/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5724 - val_loss: 1.4809\n",
      "Epoch 4/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5773 - val_loss: 1.5157\n",
      "Epoch 5/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5721 - val_loss: 1.5013\n",
      "Epoch 6/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5734 - val_loss: 1.4743\n",
      "Epoch 7/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5725 - val_loss: 1.4899\n",
      "Epoch 8/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5726 - val_loss: 1.5134\n",
      "Epoch 9/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5747 - val_loss: 1.5285\n",
      "Epoch 10/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5734 - val_loss: 1.4659\n",
      "Epoch 11/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5723 - val_loss: 1.4741\n",
      "Epoch 12/100\n",
      "793/793 [==============================] - 8s 9ms/step - loss: 1.5704 - val_loss: 1.4719\n",
      "Epoch 13/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5716 - val_loss: 1.4727\n",
      "Epoch 14/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5709 - val_loss: 1.4911\n",
      "Epoch 15/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5717 - val_loss: 1.4685\n",
      "Epoch 16/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5722 - val_loss: 1.4728\n",
      "Epoch 17/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5773 - val_loss: 1.5052\n",
      "Epoch 18/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5784 - val_loss: 1.4806\n",
      "Epoch 19/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5796 - val_loss: 1.4823\n",
      "Epoch 20/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5806 - val_loss: 1.4768\n",
      "Epoch 21/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5798 - val_loss: 1.5106\n",
      "Epoch 22/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5808 - val_loss: 1.4815\n",
      "Epoch 23/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5815 - val_loss: 1.4769\n",
      "Epoch 24/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5785 - val_loss: 1.4733\n",
      "Epoch 25/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5797 - val_loss: 1.4827\n",
      "Epoch 26/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5791 - val_loss: 1.5260\n",
      "Epoch 27/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5791 - val_loss: 1.4827\n",
      "Epoch 28/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5802 - val_loss: 1.4733\n",
      "Epoch 29/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5809 - val_loss: 1.4739\n",
      "Epoch 30/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5769 - val_loss: 1.4821\n",
      "finish 4 model\n",
      "Epoch 1/100\n",
      "793/793 [==============================] - 9s 10ms/step - loss: 1.5722 - val_loss: 1.5206\n",
      "Epoch 2/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5702 - val_loss: 1.5110\n",
      "Epoch 3/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5700 - val_loss: 1.5115\n",
      "Epoch 4/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5704 - val_loss: 1.5355\n",
      "Epoch 5/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5700 - val_loss: 1.5252\n",
      "Epoch 6/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5711 - val_loss: 1.5461\n",
      "Epoch 7/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5700 - val_loss: 1.5663\n",
      "Epoch 8/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5713 - val_loss: 1.5356\n",
      "Epoch 9/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5703 - val_loss: 1.5177\n",
      "Epoch 10/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5702 - val_loss: 1.5310\n",
      "Epoch 11/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5677 - val_loss: 1.5161\n",
      "Epoch 12/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5695 - val_loss: 1.5131\n",
      "Epoch 13/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5697 - val_loss: 1.5125\n",
      "Epoch 14/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5693 - val_loss: 1.5199\n",
      "Epoch 15/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5687 - val_loss: 1.5100\n",
      "Epoch 16/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5682 - val_loss: 1.5082\n",
      "Epoch 17/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5674 - val_loss: 1.5172\n",
      "Epoch 18/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5690 - val_loss: 1.5174\n",
      "Epoch 19/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5690 - val_loss: 1.5225\n",
      "Epoch 20/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5694 - val_loss: 1.5087\n",
      "Epoch 21/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5707 - val_loss: 1.5420\n",
      "Epoch 22/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5709 - val_loss: 1.5293\n",
      "Epoch 23/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5683 - val_loss: 1.5359\n",
      "Epoch 24/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5678 - val_loss: 1.5190\n",
      "Epoch 25/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5697 - val_loss: 1.5125\n",
      "Epoch 26/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5725 - val_loss: 1.5241\n",
      "Epoch 27/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5692 - val_loss: 1.5749\n",
      "Epoch 28/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5682 - val_loss: 1.5465\n",
      "Epoch 29/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5700 - val_loss: 1.5192\n",
      "Epoch 30/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5705 - val_loss: 1.5106\n",
      "Epoch 31/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5682 - val_loss: 1.5315\n",
      "Epoch 32/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5698 - val_loss: 1.5179\n",
      "Epoch 33/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5686 - val_loss: 1.5225\n",
      "Epoch 34/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5694 - val_loss: 1.5175\n",
      "Epoch 35/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5684 - val_loss: 1.5080\n",
      "Epoch 36/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5690 - val_loss: 1.5096\n",
      "Epoch 37/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5661 - val_loss: 1.5656\n",
      "Epoch 38/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5699 - val_loss: 1.5119\n",
      "Epoch 39/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5695 - val_loss: 1.5172\n",
      "Epoch 40/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5676 - val_loss: 1.5206\n",
      "Epoch 41/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5685 - val_loss: 1.5288\n",
      "Epoch 42/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5682 - val_loss: 1.5303\n",
      "Epoch 43/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5679 - val_loss: 1.5378\n",
      "Epoch 44/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5698 - val_loss: 1.5324\n",
      "Epoch 45/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5676 - val_loss: 1.5092\n",
      "Epoch 46/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5660 - val_loss: 1.5104\n",
      "Epoch 47/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5696 - val_loss: 1.5251\n",
      "Epoch 48/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5673 - val_loss: 1.5165\n",
      "Epoch 49/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5686 - val_loss: 1.5145\n",
      "Epoch 50/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5695 - val_loss: 1.5133\n",
      "Epoch 51/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5685 - val_loss: 1.5172\n",
      "Epoch 52/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5669 - val_loss: 1.5090\n",
      "Epoch 53/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5685 - val_loss: 1.5106\n",
      "Epoch 54/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5687 - val_loss: 1.5177\n",
      "Epoch 55/100\n",
      "793/793 [==============================] - 7s 9ms/step - loss: 1.5669 - val_loss: 1.5165\n",
      "finish 5 model\n"
     ]
    }
   ],
   "source": [
    "### KFOLD 5 함수 생성 및 적용\n",
    "\n",
    "kf=KFold(5,shuffle=True)\n",
    "i=0\n",
    "for train_index,val_index in kf.split(X):\n",
    "  i+=1\n",
    "  PCB_press_train,PCB_press_val=PCB_press[train_index],PCB_press[val_index]\n",
    "  material_weight_train,material_weight_val=material_weight[train_index],material_weight[val_index]\n",
    "  material_area_train,material_area_val=material_area[train_index],material_area[val_index]\n",
    "  pad_loc_train,pad_loc_val=pad_loc[train_index],pad_loc[val_index]\n",
    "  screw1_deep_train,screw1_deep_val=screw1_deep[train_index],screw1_deep[val_index]\n",
    "  connect_pin_train,connect_pin_val=connect_pin[train_index],connect_pin[val_index]\n",
    "  screw2_deep_train,screw2_deep_val=screw2_deep[train_index],screw2_deep[val_index]\n",
    "  screw_rotate_train,screw_rotate_val=screw_rotate[train_index],screw_rotate[val_index]\n",
    "  housing_train,housing_val=housing[train_index],housing[val_index]\n",
    "  radom_train,radom_val=radom[train_index],radom[val_index]\n",
    "  RF_train,RF_val=RF[train_index],RF[val_index]\n",
    "  \n",
    "  y_train,y_val=y[train_index],y[val_index]\n",
    "  model=fit_model(PCB_press_train,material_weight_train,material_area_train,pad_loc_train,screw1_deep_train,connect_pin_train,screw2_deep_train,screw_rotate_train,housing_train,radom_train,RF_train,PCB_press_val,material_weight_val,material_area_val,pad_loc_val,screw1_deep_val,connect_pin_val,screw2_deep_val,screw_rotate_val,housing_val,radom_val,RF_val,y_train,y_val,i)\n",
    "  print('finish {} model'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1s 5ms/step - loss: 1.5020\n",
      "1.5020248889923096\n",
      "199/199 [==============================] - 1s 4ms/step - loss: 1.5019\n",
      "1.5019190311431885\n",
      "199/199 [==============================] - 1s 4ms/step - loss: 1.5012\n",
      "1.5012356042861938\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 1.5004\n",
      "1.5004385709762573\n",
      "199/199 [==============================] - 1s 5ms/step - loss: 1.5080\n",
      "1.5080111026763916\n"
     ]
    }
   ],
   "source": [
    "### 5개의 앙상블 모델 로딩\n",
    "model1=load_model(\"C:/LG_Aimers/Conv/model/fold1--.1.557.h5\")\n",
    "print(model1.evaluate([PCB_press_val,material_weight_val,material_area_val,pad_loc_val,screw1_deep_val,connect_pin_val,screw2_deep_val,screw_rotate_val,housing_val,radom_val,RF_val],y_val))\n",
    "\n",
    "model2=load_model(\"C:/LG_Aimers/Conv/model/fold2--.1.619.h5\")\n",
    "print(model2.evaluate([PCB_press_val,material_weight_val,material_area_val,pad_loc_val,screw1_deep_val,connect_pin_val,screw2_deep_val,screw_rotate_val,housing_val,radom_val,RF_val],y_val))\n",
    "\n",
    "model3=load_model(\"C:/LG_Aimers/Conv/model/fold3--.1.568.h5\")\n",
    "print(model3.evaluate([PCB_press_val,material_weight_val,material_area_val,pad_loc_val,screw1_deep_val,connect_pin_val,screw2_deep_val,screw_rotate_val,housing_val,radom_val,RF_val],y_val))\n",
    "\n",
    "model4=load_model(\"C:/LG_Aimers/Conv/model/fold4--.1.466.h5\")\n",
    "print(model4.evaluate([PCB_press_val,material_weight_val,material_area_val,pad_loc_val,screw1_deep_val,connect_pin_val,screw2_deep_val,screw_rotate_val,housing_val,radom_val,RF_val],y_val))\n",
    "\n",
    "model5=load_model(\"C:/LG_Aimers/Conv/model/fold5--.1.508.h5\")\n",
    "print(model5.evaluate([PCB_press_val,material_weight_val,material_area_val,pad_loc_val,screw1_deep_val,connect_pin_val,screw2_deep_val,screw_rotate_val,housing_val,radom_val,RF_val],y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5개의 앙상블 모델 합치기\n",
    "all_models=list([model1,model2,model3,model4,model5])\n",
    "  \n",
    "def define_stacked_model(members):\n",
    "  # update all layers in all models to not be trainiable\n",
    "  for i in range(len(members)):\n",
    "    model=members[i]\n",
    "    for layer in model.layers:\n",
    "      layer.trainable=False\n",
    "      # rename to avoid 'unique layer name' issue\n",
    "      layer._name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
    "  \n",
    "  # define multi-handed input\n",
    "  ensemble_visible=[model.input for model in members]\n",
    "  ensemble_outputs=[model.output for model in members]\n",
    "\n",
    "  y=Average()(ensemble_outputs)\n",
    "\n",
    "  model=Model(inputs=ensemble_visible,outputs=y,name='ensemble')\n",
    "\n",
    "  keras.utils.plot_model(model,show_shapes=True,to_file='C:\\LG_Aimers\\XGB노가다\\Y_03_결과\\model_graph.jpg')\n",
    "\n",
    "  model.compile(loss='mae',optimizer='adam')\n",
    "  return model\n",
    "\n",
    "def fit_stacked_model(model,trainX,valX,trainY,valY):\n",
    "  x_train=[trainX for _ in range(len(model.input))]\n",
    "  x_val=[valX for _ in range(len(model.input))]\n",
    "  y_train=trainY\n",
    "  y_val=valY\n",
    "\n",
    "  es=keras.callbacks.EarlyStopping(monitor='val_loss',patience=20)\n",
    "  checkpoint_filepath='/content/drive/MyDrive/lg aimers/ensemble_model.h5'\n",
    "  cp=keras.callbacks.ModelCheckpoint(\n",
    "      filepath=checkpoint_filepath,\n",
    "      monitor='val_loss',\n",
    "      save_best_only=True\n",
    "  )\n",
    "  model.fit(x_train,y_train,epochs=1,validation_data=(x_val,y_val),callbacks=[es,cp],batch_size=32)\n",
    "\n",
    "def evaluate_stacked_model(model,inputX,y_val):\n",
    "  x_val=[inputX for _ in range(len(model.input))]\n",
    "  return model.evaluate(x_val,y_val)\n",
    "\n",
    "def predict_stacked_model(model,inputX):\n",
    "  x_test=[inputX for _ in range(len(model.input))]\n",
    "  return model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/793 [==============================] - 18s 19ms/step - loss: 0.7130 - val_loss: 0.7032\n"
     ]
    }
   ],
   "source": [
    "### 모델 스태킹하기\n",
    "n_members=5\n",
    "members=all_models\n",
    "\n",
    "stacked_model=define_stacked_model(members)\n",
    "fit_stacked_model(stacked_model,[PCB_press_train,material_weight_train,material_area_train,pad_loc_train,screw1_deep_train,connect_pin_train,screw2_deep_train,screw_rotate_train,housing_train,radom_train,RF_train],[PCB_press_val,material_weight_val,material_area_val,pad_loc_val,screw1_deep_val,connect_pin_val,screw2_deep_val,screw_rotate_val,housing_val,radom_val,RF_val],y_train,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 3s 15ms/step - loss: 0.7032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7031537890434265"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Stacking 모델 평가하기\n",
    "evaluate_stacked_model(stacked_model,[PCB_press_val,material_weight_val,material_area_val,pad_loc_val,screw1_deep_val,connect_pin_val,screw2_deep_val,screw_rotate_val,housing_val,radom_val,RF_val],y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 따로 나눈 데이터로 테스트 ###\n",
    "X_valid = pd.read_csv(\"C:/LG_Aimers/data/Train-Test-Split/X_train.csv\")\n",
    "y_valid = pd.read_csv(\"C:/LG_Aimers/data/Train-Test-Split/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Seperate\n",
    "PCB_press_valid = X_valid[[\"X_01\",\"X_02\",\"X_05\",\"X_06\"]]\n",
    "material_weight_valid = X_valid[[\"X_03\",\"X_10\",\"X_11\"]]\n",
    "material_area_valid = X_valid[[\"X_07\",\"X_08\",\"X_09\"]]\n",
    "pad_loc_valid = X_valid[[\"X_14\",\"X_15\",\"X_16\",\"X_17\",\"X_18\",\"X_13\"]]\n",
    "screw1_deep_valid = X_valid[[\"X_19\",\"X_20\",\"X_21\",\"X_22\"]]\n",
    "connect_pin_valid = X_valid[[\"X_24\",\"X_25\",\"X_26\",\"X_27\",\"X_28\",\"X_29\",\"X_12\"]]\n",
    "screw2_deep_valid = X_valid[[\"X_30\",\"X_31\",\"X_32\",\"X_33\"]]\n",
    "screw_rotate_valid = X_valid[[\"X_34\",\"X_35\",\"X_36\",\"X_37\"]]\n",
    "housing_valid = X_valid[[\"X_38\",\"X_39\",\"X_40\",\"X_46\"]]\n",
    "radom_valid = X_valid[[\"X_41\",\"X_42\",\"X_43\",\"X_44\",\"X_45\"]]\n",
    "RF_valid = X_valid[[\"X_49\",\"X_50\",\"X_51\",\"X_52\",\"X_53\",\"X_54\",\"X_55\",\"X_56\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stacking\n",
    "result=predict_stacked_model(stacked_model,[PCB_press_valid,material_weight_valid,material_area_valid,pad_loc_valid,screw1_deep_valid,connect_pin_valid,screw2_deep_valid,screw_rotate_valid,housing_valid,radom_valid,RF_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 정답 데이터\n",
    "y_valid_array = np.array(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scoring 함수 생성\n",
    "def lg_nrmse(gt, preds):\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    all_nrmse = []\n",
    "    for idx in range(0,14): # ignore 'ID'\n",
    "        rmse = metrics.mean_squared_error(gt[:,idx], preds[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:15])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0156351596250097"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 결과 도출\n",
    "lg_nrmse(y_valid_array, result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8c8540e0960871b600e3f40e1e37dd4369b4892e9ee484b4784a47d7408b04b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
