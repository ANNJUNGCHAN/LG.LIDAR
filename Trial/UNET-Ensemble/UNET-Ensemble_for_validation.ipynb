{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNET-Ensemble\n",
    "- UNET의 구조에 착안하여 만든 모델\n",
    "- UNET의 구조처럼 잠재벡터를 단계적으로 만들어 나가면서, 단계별로 잠재벡터를 형성한다.\n",
    "- UNET의 최하단에 진입했을 때, 다시 상단으로 올라오면서 예측값을 생성한다.\n",
    "- 이 때, 상단으로 올라오는 단계별로 하단에서 만든 잠재벡터들을 아래에서 위로 끌어오면서, 모델이 하단으로 가면서 잃어버렸던 정보량을 최대한 보전하려고 노력한다.\n",
    "- 이 후, 최 상단에서는 최 하단으로 진입하는 단계에서 단계적으로 생성한 잠재벡터들을 모두 고려한 결과값을 도출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패키지 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Seed 고정\n",
    "import random\n",
    "import os\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) \n",
    "\n",
    "# Keras and Tensorflow\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Dense,Dropout,BatchNormalization,Add,Input,Activation,Concatenate,Average\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "# Scoring\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 로딩\n",
    "X = pd.read_csv(\"C:/LG_Aimers/data/Train-Test-Split/X_train.csv\")\n",
    "y = pd.read_csv(\"C:/LG_Aimers/data/Train-Test-Split/y_train.csv\")\n",
    "\n",
    "### 딥러닝 학습을 위한 데이터 넘파이 변환\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 구축\n",
    "\n",
    "# input 정의\n",
    "input_layer = keras.layers.Input(shape=(56,), dtype=\"float32\")\n",
    "\n",
    "# go to deep\n",
    "go1 = keras.layers.Dense(32, activation=\"relu\",kernel_initializer=\"he_normal\")(input_layer)\n",
    "go2 = keras.layers.Dense(32, activation=\"relu\",kernel_initializer=\"he_normal\")(go1)\n",
    "batch1 = keras.layers.BatchNormalization()(go2)\n",
    "go3 = keras.layers.Dense(64, activation=\"relu\",kernel_initializer=\"he_normal\")(batch1)\n",
    "go4 = keras.layers.Dense(64, activation=\"relu\",kernel_initializer=\"he_normal\")(go3)\n",
    "batch2 = keras.layers.BatchNormalization()(go4)\n",
    "go5 = keras.layers.Dense(128, activation=\"relu\",kernel_initializer=\"he_normal\")(batch2)\n",
    "go6 = keras.layers.Dense(128, activation=\"relu\",kernel_initializer=\"he_normal\")(go5)\n",
    "batch3 = keras.layers.BatchNormalization()(go6)\n",
    "go7 = keras.layers.Dense(256, activation=\"relu\",kernel_initializer=\"he_normal\")(batch3)\n",
    "go8 = keras.layers.Dense(256, activation=\"relu\",kernel_initializer=\"he_normal\")(go7)\n",
    "batch4 = keras.layers.BatchNormalization()(go8)\n",
    "go9 = keras.layers.Dense(512, activation=\"relu\",kernel_initializer=\"he_normal\")(batch4)\n",
    "go10 = keras.layers.Dense(512, activation=\"relu\",kernel_initializer=\"he_normal\")(go9)\n",
    "batch5 = keras.layers.BatchNormalization()(go10)\n",
    "\n",
    "# go to up\n",
    "up1 = keras.layers.Dense(256, activation=\"relu\",kernel_initializer=\"he_normal\")(batch5)\n",
    "up2 = keras.layers.Dense(256, activation=\"relu\",kernel_initializer=\"he_normal\")(up1)\n",
    "concat1 = keras.layers.Concatenate()([go8 ,up2])\n",
    "up3 = keras.layers.Dense(128, activation=\"relu\",kernel_initializer=\"he_normal\")(concat1)\n",
    "up4 = keras.layers.Dense(128, activation=\"relu\",kernel_initializer=\"he_normal\")(up3)\n",
    "concat2 = keras.layers.Concatenate()([go6, up4])\n",
    "up5 = keras.layers.Dense(64, activation=\"relu\",kernel_initializer=\"he_normal\")(concat2)\n",
    "up6 = keras.layers.Dense(64, activation=\"relu\",kernel_initializer=\"he_normal\")(up5)\n",
    "concat3 = keras.layers.Concatenate()([go4, up6])\n",
    "up7 = keras.layers.Dense(32, activation=\"relu\",kernel_initializer=\"he_normal\")(concat3)\n",
    "up8 = keras.layers.Dense(32, activation=\"relu\",kernel_initializer=\"he_normal\")(up7)\n",
    "concat4 = keras.layers.Concatenate()([go2, up8])\n",
    "\n",
    "# result\n",
    "result_layer = keras.layers.Dense(14)(concat4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 Fitting 함수 정의\n",
    "def fit_model(X_train,X_val,y_train,y_val,i): \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer,\n",
    "        outputs=result_layer)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath = 'C:/LG_Aimers/U_NET_ALL/model/'+'fold' + str(i) + '--.{val_loss:.3f}'+'.h5', \n",
    "        monitor='val_loss', \n",
    "        save_best_only=True)\n",
    "    model.fit(X_train, \n",
    "              y_train,\n",
    "              batch_size=32,\n",
    "              epochs=300, \n",
    "              validation_data=(X_val, y_val), \n",
    "              callbacks=[early_stopping, checkpoint])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 학습\n",
    "kf=KFold(10,shuffle=True)\n",
    "i=0\n",
    "for train_index,val_index in kf.split(X):\n",
    "  i+=1\n",
    "  X_train,X_val=X[train_index],X[val_index]\n",
    "  y_train,y_val=y[train_index],y[val_index]\n",
    "  model=fit_model(X_train,X_val,y_train,y_val,i)\n",
    "  print('finish {} model'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KFOLD 10 Model 불러오기\n",
    "model1=load_model(\"C:/LG_Aimers/U_NET_ALL/model/fold1--.1.526.h5\")\n",
    "model2=load_model(\"C:/LG_Aimers/DENSE_CHAIN/model/fold2--.1.632.h5\")\n",
    "model3=load_model(\"C:/LG_Aimers/U_NET_ALL/model/fold3--.1.742.h5\")\n",
    "model4=load_model(\"C:/LG_Aimers/U_NET_ALL/model/fold4--.1.528.h5\")\n",
    "model5=load_model(\"C:/LG_Aimers/U_NET_ALL/model/fold5--.1.431.h5\")\n",
    "model6=load_model(\"C:/LG_Aimers/U_NET_ALL/model/fold6--.1.720.h5\")\n",
    "model7=load_model(\"C:/LG_Aimers/U_NET_ALL/model/fold7--.1.479.h5\")\n",
    "model8=load_model(\"C:/LG_Aimers/U_NET_ALL/model/fold8--.1.574.h5\")\n",
    "model9=load_model(\"C:/LG_Aimers/U_NET_ALL/model/fold9--.1.507.h5\")\n",
    "model10=load_model(\"C:/LG_Aimers/U_NET_ALL/model/fold10--.1.513.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 앙상블 모델 형성\n",
    "all_models=list([model1,model3,model4,model5,model6,model7,model8,model9,model10])\n",
    "\n",
    "### 앙상블 모델 정의 함수 구축\n",
    "def define_stacked_model(members):\n",
    "  # update all layers in all models to not be trainiable\n",
    "  for i in range(len(members)):\n",
    "    model=members[i]\n",
    "    for layer in model.layers:\n",
    "      layer.trainable=False\n",
    "      # rename to avoid 'unique layer name' issue\n",
    "      layer._name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
    "  \n",
    "  # define multi-handed input\n",
    "  ensemble_visible=[model.input for model in members]\n",
    "  ensemble_outputs=[model.output for model in members]\n",
    "\n",
    "  y=Average()(ensemble_outputs)\n",
    "\n",
    "  model=Model(inputs=ensemble_visible,outputs=y,name='ensemble')\n",
    "\n",
    "  keras.utils.plot_model(model,show_shapes=True,to_file='C:\\LG_Aimers\\XGB노가다\\Y_03_결과\\model_graph.jpg')\n",
    "\n",
    "  model.compile(loss='mae',optimizer='adam')\n",
    "  return model\n",
    "\n",
    "### 앙상블 모델 Fitting 함수 구축\n",
    "def fit_stacked_model(model,trainX,valX,trainY,valY):\n",
    "  x_train=[trainX for _ in range(len(model.input))]\n",
    "  x_val=[valX for _ in range(len(model.input))]\n",
    "  y_train=trainY\n",
    "  y_val=valY\n",
    "\n",
    "  es=keras.callbacks.EarlyStopping(monitor='val_loss',patience=20)\n",
    "  checkpoint_filepath='/content/drive/MyDrive/lg aimers/ensemble_model.h5'\n",
    "  cp=keras.callbacks.ModelCheckpoint(\n",
    "      filepath=checkpoint_filepath,\n",
    "      monitor='val_loss',\n",
    "      save_best_only=True\n",
    "  )\n",
    "  model.fit(x_train,y_train,epochs=1,validation_data=(x_val,y_val),callbacks=[es,cp],batch_size=32)\n",
    "\n",
    "\n",
    "### 앙상블모델 평가함수 구축\n",
    "def evaluate_stacked_model(model,inputX,y_val):\n",
    "  x_val=[inputX for _ in range(len(model.input))]\n",
    "  return model.evaluate(x_val,y_val)\n",
    "\n",
    "### 앙상블모델 예측함수 구축\n",
    "def predict_stacked_model(model,inputX):\n",
    "  x_test=[inputX for _ in range(len(model.input))]\n",
    "  return model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 앙상블모델 학습 및 평가\n",
    "n_members=10\n",
    "members=all_models\n",
    "\n",
    "stacked_model=define_stacked_model(members)\n",
    "fit_stacked_model(stacked_model,X_train,X_val,y_train,y_val)\n",
    "\n",
    "evaluate_stacked_model(stacked_model,X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 로딩\n",
    "X_valid = pd.read_csv(\"C:/LG_Aimers/data/Train-Test-Split/X_valid.csv\")\n",
    "y_valid = pd.read_csv(\"C:/LG_Aimers/data/Train-Test-Split/y_valid.csv\")\n",
    "\n",
    "### 앙상블 모델 예측\n",
    "result=predict_stacked_model(stacked_model,X_valid)\n",
    "\n",
    "### 예측 결과 넘파이 변환\n",
    "y_valid_array = np.array(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 평가함수 구축\n",
    "def lg_nrmse(gt, preds):\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    all_nrmse = []\n",
    "    for idx in range(0,14): # ignore 'ID'\n",
    "        rmse = metrics.mean_squared_error(gt[:,idx], preds[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:15])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 스코어 계산\n",
    "lg_nrmse(y_valid_array, result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8c8540e0960871b600e3f40e1e37dd4369b4892e9ee484b4784a47d7408b04b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
